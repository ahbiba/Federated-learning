{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905d8b4c",
   "metadata": {},
   "source": [
    "\n",
    "# **Apprentissage Fédéré avec Cryptage des Poids**\n",
    "\n",
    "Ce notebook implémente un exemple simple d'apprentissage fédéré, où un client entraîne un modèle localement, crypte les poids du modèle, et les envoie à un serveur pour agrégation. Le serveur reçoit ces poids cryptés, les décrypte, les agrège avec les poids globaux et met à jour le modèle global.\n",
    "\n",
    "Le cryptage des poids est effectué pour préserver la confidentialité des données des utilisateurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4a9c7",
   "metadata": {},
   "source": [
    "## **Étape 1 : Importation des bibliothèques nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import requests\n",
    "import numpy as np\n",
    "import base64\n",
    "import pickle\n",
    "import cryptage\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_local_model():\n",
    "    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "\n",
    "    model = build_model()\n",
    "    model.fit(x_train, y_train, epochs=1, batch_size=32, verbose=2)\n",
    "\n",
    "    weights = model.get_weights()\n",
    "    encrypted_weights = cryptage.encrypt_weights(weights)\n",
    "\n",
    "    url = \"http://localhost:5000/update_model\"\n",
    "    response = requests.post(url, json={'weights': encrypted_weights})\n",
    "    print(\"Réponse du serveur : \", response.text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_local_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4997b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server.py\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import tensorflow as tf\n",
    "import cryptage\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "global_model = build_model()\n",
    "\n",
    "@app.route('/update_model', methods=['POST'])\n",
    "def update_model():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        if 'weights' not in data:\n",
    "            return jsonify({\"error\": \"Aucun poids envoyé.\"}), 400\n",
    "\n",
    "        encrypted_weights_b64 = data['weights']\n",
    "        decrypted_weights = cryptage.decrypt_weights(encrypted_weights_b64)\n",
    "\n",
    "        global_weights = global_model.get_weights()\n",
    "        if len(decrypted_weights) != len(global_weights):\n",
    "            return jsonify({\"error\": \"Les tailles des poids sont incompatibles.\"}), 400\n",
    "\n",
    "        for i in range(len(global_weights)):\n",
    "            global_weights[i] = (global_weights[i] + decrypted_weights[i]) / 2\n",
    "\n",
    "        global_model.set_weights(global_weights)\n",
    "        global_model.save_weights(\"model_weights.h5\")\n",
    "        print(\"Poids du modèle enregistrés.\")\n",
    "\n",
    "        return jsonify({\"message\": \"Modèle mis à jour avec succès.\"})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55229b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cryptage.py\n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "import base64\n",
    "import pickle\n",
    "\n",
    "SHARED_KEY = b'm2eJGGTAoknU0JUPO7O0Ume024lipzhsT1Bf5ag3YE8='\n",
    "fernet = Fernet(SHARED_KEY)\n",
    "\n",
    "def encrypt_weights(weights):\n",
    "    serialized = pickle.dumps(weights)\n",
    "    encrypted = fernet.encrypt(serialized)\n",
    "    return base64.b64encode(encrypted).decode('utf-8')\n",
    "\n",
    "def decrypt_weights(encrypted_b64):\n",
    "    encrypted = base64.b64decode(encrypted_b64.encode('utf-8'))\n",
    "    decrypted = fernet.decrypt(encrypted)\n",
    "    return pickle.loads(decrypted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1242fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.load_weights(\"model_weights.h5\")\n",
    "print(\"Poids rechargés avec succès.\")\n",
    "\n",
    "(_, _), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Accuracy sur les données test : {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
