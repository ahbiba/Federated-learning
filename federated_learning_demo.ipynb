# **Apprentissage Fédéré avec Cryptage des Poids**

Ce notebook implémente un exemple simple d'apprentissage fédéré, où un client entraîne un modèle localement, crypte les poids du modèle, et les envoie à un serveur pour agrégation. Le serveur reçoit ces poids cryptés, les décrypte, les agrège avec les poids globaux et met à jour le modèle global.

Le cryptage des poids est effectué pour préserver la confidentialité des données des utilisateurs.

---

## **Étape 1 : Importation des bibliothèques nécessaires**

Dans cette étape, nous importons toutes les bibliothèques nécessaires à notre projet, telles que TensorFlow pour le modèle de machine learning et des bibliothèques pour le chiffrement des poids.

```python
# Importation de TensorFlow et des outils nécessaires
import tensorflow as tf
from tensorflow.keras import layers, models
import requests
import numpy as np
import base64
import pickle
import cryptage


# client.py

def build_model():
    """
    Crée un modèle de réseau de neurones simple pour la classification des images MNIST.
    """
    model = models.Sequential([
        layers.Flatten(input_shape=(28, 28, 1)),  # Entrée : image 28x28 en niveaux de gris
        layers.Dense(128, activation='relu'),    # Couche cachée avec 128 neurones
        layers.Dropout(0.2),                     # Dropout pour régularisation
        layers.Dense(10, activation='softmax')   # Couche de sortie pour les 10 classes
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

def train_local_model():
    """
    Entraîne un modèle local sur les données MNIST et envoie les poids cryptés au serveur.
    """
    # Charger les données MNIST
    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()
    x_train = x_train.astype('float32') / 255.0  # Normalisation des images
    x_train = np.reshape(x_train, (-1, 28, 28, 1))  # Reshape pour correspondre à l'entrée du modèle

    # Créer et entraîner le modèle localement
    model = build_model()
    model.fit(x_train, y_train, epochs=1, batch_size=32, verbose=2)  # Entraînement pendant 1 époque

    # Extraire les poids et les crypter
    weights = model.get_weights()
    encrypted_weights = cryptage.encrypt_weights(weights)

    # Envoyer les poids cryptés au serveur
    url = "http://localhost:5000/update_model"
    response = requests.post(url, json={'weights': encrypted_weights})
    print("Réponse du serveur : ", response.text)

if __name__ == '__main__':
    train_local_model()

# server.py

from flask import Flask, request, jsonify
import tensorflow as tf
import cryptage

app = Flask(__name__)

def build_model():
    """
    Crée un modèle de réseau de neurones similaire au client pour l'agrégation des poids.
    """
    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Modèle global
global_model = build_model()

@app.route('/update_model', methods=['POST'])
def update_model():
    """
    Reçoit les poids cryptés, les décrypte, les agrège avec le modèle global et sauvegarde les poids.
    """
    try:
        data = request.get_json()
        if 'weights' not in data:
            return jsonify({"error": "Aucun poids envoyé."}), 400

        # Décryptage des poids
        encrypted_weights_b64 = data['weights']
        decrypted_weights = cryptage.decrypt_weights(encrypted_weights_b64)

        # Agrégation des poids avec le modèle global
        global_weights = global_model.get_weights()
        if len(decrypted_weights) != len(global_weights):
            return jsonify({"error": "Les tailles des poids sont incompatibles."}), 400

        # Moyenne des poids
        for i in range(len(global_weights)):
            global_weights[i] = (global_weights[i] + decrypted_weights[i]) / 2

        # Mise à jour des poids du modèle global
        global_model.set_weights(global_weights)

        # Sauvegarde des poids dans un fichier
        global_model.save_weights("model_weights.h5")
        print(f"Poids du modèle enregistrés.")

        return jsonify({"message": "Modèle mis à jour avec succès."})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)  # Lancement du serveur Flask

# cryptage.py

from cryptography.fernet import Fernet
import base64
import pickle
import tensorflow as tf

# Clé de chiffrement partagée 
SHARED_KEY = b'm2eJGGTAoknU0JUPO7O0Ume024lipzhsT1Bf5ag3YE8='  

fernet = Fernet(SHARED_KEY)

def encrypt_weights(weights):
    """
    Crypte les poids du modèle à l'aide de Fernet et les encode en base64 pour la transmission.
    """
    # Sérialisation des poids
    serialized = pickle.dumps(weights)
    encrypted = fernet.encrypt(serialized)
    # Encodage base64 pour transmission JSON-safe
    return base64.b64encode(encrypted).decode('utf-8')

def decrypt_weights(encrypted_b64):
    """
    Décrypte les poids reçus et les désérialise pour les récupérer sous forme de liste de poids.
    """
    encrypted = base64.b64decode(encrypted_b64.encode('utf-8'))
    decrypted = fernet.decrypt(encrypted)
    return pickle.loads(decrypted)


# model.py

#  Étape 1 : Redéfinir l'architecture du modèle
def build_model():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Étape 2 : Créer le modèle
model = build_model()

# Étape 3 : Charger les poids depuis les fichiers générés
model.load_weights("model_weights")  
print("Poids rechargés avec succès.")

# Étape 4  : Faire une prédiction ou évaluer le modèle
(_, _), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_test = x_test.astype('float32') / 255.0
x_test = x_test.reshape(-1, 28, 28, 1)

loss, acc = model.evaluate(x_test, y_test, verbose=2)
print(f"Accuracy sur les données test : {acc:.4f}")

# **Démarrage du serveur et du client**

### Démarrer le serveur

Pour démarrer le serveur, vous devez exécuter le fichier `server.py`. Le serveur attendra que le client envoie les poids cryptés pour pouvoir les décrypter, les agréger et mettre à jour le modèle global.

Ouvrez un terminal et exécutez la commande suivante :

python server.py

#Ouvrez un autre terminal et exécutez la commande suivante :
python client.py

###Explications supplémentaires :
Client (client.py) : Le client entraîne un modèle localement sur le dataset MNIST, crypte les poids du modèle et les envoie au serveur pour l'agrégation.

Serveur (server.py) : Le serveur reçoit les poids cryptés, les décrypte, les agrège avec les poids existants, puis met à jour le modèle global.

cryptage (cryptage.py) : Ce fichier contient des fonctions pour crypter et décrypter les poids du modèle en utilisant Fernet, un algorithme de chiffrement symétrique.

Résultat de la féderation (model.py): ce fichier permet de recharger les poids du modèle fédéré enregistrés pendant l'entraînement (dans le fichier model_weights) et de réévaluer sa performance sur les données de test MNIST

